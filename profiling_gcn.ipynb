{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from pygcn.gcnio.data import dataio\n",
    "from pygcn.gcnio.util import utils\n",
    "from pygcn.gcn import GCN\n",
    "import scipy.sparse\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import glog as log\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print('cuda: %s' % cuda)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(prefix, normalize=True):\n",
    "    adj_full = scipy.sparse.load_npz('./{}/adj_full.npz'.format(prefix))\n",
    "    adj_train = scipy.sparse.load_npz('./{}/adj_train.npz'.format(prefix))\n",
    "    role = json.load(open('./{}/role.json'.format(prefix)))\n",
    "    feats = np.load('./{}/feats.npy'.format(prefix))\n",
    "    class_map = json.load(open('./{}/class_map.json'.format(prefix)))\n",
    "    class_map = {int(k):v for k,v in class_map.items()}\n",
    "    assert len(class_map) == feats.shape[0]\n",
    "    # ---- normalize feats ----\n",
    "    train_nodes = np.array(list(set(adj_train.nonzero()[0])))\n",
    "    train_feats = feats[train_nodes]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_feats)\n",
    "    feats = scaler.transform(feats)\n",
    "    # -------------------------\n",
    "    return adj_full, adj_train, feats, class_map, role\n",
    "\n",
    "\n",
    "def process_graph_data(adj_full, adj_train, feats, class_map, role):\n",
    "    \"\"\"\n",
    "    setup vertex property map for output classes, train/val/test masks, and feats\n",
    "    INPUT:\n",
    "        G           graph-tool graph, full graph including training,val,testing\n",
    "        feats       ndarray of shape |V|xf\n",
    "        class_map   dictionary {vertex_id: class_id}\n",
    "        val_nodes   index of validation nodes\n",
    "        test_nodes  index of testing nodes\n",
    "    OUTPUT:\n",
    "        G           graph-tool graph unchanged\n",
    "        role        array of size |V|, indicating 'train'/'val'/'test'\n",
    "        class_arr   array of |V|x|C|, converted by class_map\n",
    "        feats       array of features unchanged\n",
    "    \"\"\"\n",
    "    num_vertices = adj_full.shape[0]\n",
    "    if isinstance(list(class_map.values())[0],list):\n",
    "        print(\"labels are list\")\n",
    "        num_classes = len(list(class_map.values())[0])\n",
    "        class_arr = np.zeros((num_vertices, num_classes))\n",
    "        for k,v in class_map.items():\n",
    "            class_arr[k] = v\n",
    "    else:\n",
    "        num_classes = max(class_map.values()) - min(class_map.values()) + 1\n",
    "        class_arr = np.zeros((num_vertices, 1))\n",
    "        for k,v in class_map.items():\n",
    "            class_arr[k] = v\n",
    "    return adj_full, adj_train, feats, class_arr.astype(int), role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0228 19:50:19.497399 864 <ipython-input-15-c1f0a11b40fd>:37] <class 'scipy.sparse.csr.csr_matrix'>\n",
      "I0228 19:50:19.498293 864 <ipython-input-15-c1f0a11b40fd>:38] (89250, 89250)\n",
      "I0228 19:50:19.498900 864 <ipython-input-15-c1f0a11b40fd>:39] <class 'scipy.sparse.csr.csr_matrix'>\n",
      "I0228 19:50:19.499469 864 <ipython-input-15-c1f0a11b40fd>:40] (89250, 89250)\n",
      "I0228 19:50:19.500033 864 <ipython-input-15-c1f0a11b40fd>:41] <class 'scipy.sparse.csr.csr_matrix'>\n",
      "I0228 19:50:19.500581 864 <ipython-input-15-c1f0a11b40fd>:42] (89250, 500)\n",
      "I0228 19:50:19.501123 864 <ipython-input-15-c1f0a11b40fd>:43] <class 'numpy.ndarray'>\n",
      "I0228 19:50:19.501703 864 <ipython-input-15-c1f0a11b40fd>:44] (89250, 1)\n",
      "I0228 19:50:19.502253 864 <ipython-input-15-c1f0a11b40fd>:45] <class 'numpy.ndarray'>\n",
      "I0228 19:50:19.502799 864 <ipython-input-15-c1f0a11b40fd>:46] <class 'numpy.ndarray'>\n",
      "I0228 19:50:19.503351 864 <ipython-input-15-c1f0a11b40fd>:47] (44625,)\n",
      "I0228 19:50:19.503894 864 <ipython-input-15-c1f0a11b40fd>:48] <class 'numpy.ndarray'>\n",
      "I0228 19:50:19.504436 864 <ipython-input-15-c1f0a11b40fd>:49] (22312,)\n",
      "I0228 19:50:19.504980 864 <ipython-input-15-c1f0a11b40fd>:50] <class 'numpy.ndarray'>\n",
      "I0228 19:50:19.505553 864 <ipython-input-15-c1f0a11b40fd>:51] (22313,)\n"
     ]
    }
   ],
   "source": [
    "# make sure you use the same data splits as you generated attacks\n",
    "seed = 15\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "# load original dataset (to get clean features and labels)\n",
    "SMALL = True\n",
    "if SMALL:\n",
    "    dataset = 'polblogs'\n",
    "    data = dataio.Dataset(root='/tmp/', name=dataset)\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "    \n",
    "    log.info(type(adj))\n",
    "    log.info(adj.shape)\n",
    "    log.info(type(features))\n",
    "    log.info(features.shape)\n",
    "    log.info(type(labels))\n",
    "    log.info(labels.shape)\n",
    "    log.info(type(idx_train))\n",
    "    log.info(idx_train.shape)\n",
    "    log.info(type(idx_val))\n",
    "    log.info(idx_val.shape)\n",
    "    log.info(type(idx_test))\n",
    "    log.info(idx_test.shape)\n",
    "else:\n",
    "    data_prefix = './data/flickr'\n",
    "    temp_data = load_data(data_prefix)\n",
    "    train_data = process_graph_data(*temp_data)\n",
    "    adj,adj_train,features,labels,role = train_data\n",
    "    features = scipy.sparse.csr_matrix(features)\n",
    "    idx_train = np.array(role['tr'])\n",
    "    idx_val = np.array(role['va'])\n",
    "    idx_test = np.array(role['te'])\n",
    "    log.info(type(adj))\n",
    "    log.info(adj.shape)\n",
    "    log.info(type(adj_train))\n",
    "    log.info(adj_train.shape)\n",
    "    log.info(type(features))\n",
    "    log.info(features.shape)\n",
    "    log.info(type(labels))\n",
    "    log.info(labels.shape)\n",
    "    log.info(type(labels[0]))\n",
    "    log.info(type(idx_train))\n",
    "    log.info(idx_train.shape)\n",
    "    log.info(type(idx_val))\n",
    "    log.info(idx_val.shape)\n",
    "    log.info(type(idx_test))\n",
    "    log.info(idx_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(labels.max())\n",
    "\n",
    "# Model and optimizer\n",
    "if len(labels.shape)>1:\n",
    "    model = GCN(nfeat=features.shape[1], nhid=32, nclass=len(labels[0]), device=device)\n",
    "else:\n",
    "    model = GCN(nfeat=features.shape[1], nhid=32, nclass=labels.max()+1, device=device)\n",
    "    \n",
    "    \n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3579b9507698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# # using validation to pick model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model.fit(features, perturbed_adj, labels, idx_train, idx_val, train_iters=200, verbose=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2020/gcn/pygcn/gcn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, adj, labels, idx_train, idx_val, train_iters, initialize, verbose, normalize, patience)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_without_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtrain_iters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2020/gcn/pygcn/gcn.py\u001b[0m in \u001b[0;36m_train_without_val\u001b[0;34m(self, labels, idx_train, train_iters, verbose)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2265\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "model.fit(features, adj, labels, idx_train, train_iters=200, verbose=True)\n",
    "# # using validation to pick model\n",
    "# model.fit(features, perturbed_adj, labels, idx_train, idx_val, train_iters=200, verbose=True)\n",
    "model.eval()\n",
    "# You can use the inner function of model to test\n",
    "model.test(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
